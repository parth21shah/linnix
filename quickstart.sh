#!/bin/bash
# Linnix Quick Start Script
# Gets you from zero to AI-powered insights in < 5 minutes

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Banner
echo ""
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘                                                            â•‘"
echo "â•‘   ğŸš€  Linnix Quick Start                                   â•‘"
echo "â•‘   eBPF Monitoring + AI Incident Detection                 â•‘"
echo "â•‘                                                            â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# Parse args
AUTO_DEMO=0
for arg in "$@"; do
    case "$arg" in
        --autodemo|-d)
            AUTO_DEMO=1
            ;;
        --help|-h)
            echo "Usage: $0 [--autodemo|-d]";
            exit 0
            ;;
    esac
done

# Step 1: Check prerequisites
echo -e "${BLUE}[1/6]${NC} Checking prerequisites..."

# Check Docker
if ! command -v docker &> /dev/null; then
    echo -e "${RED}âŒ Docker not found${NC}"
    echo "   Install Docker: https://docs.docker.com/get-docker/"
    exit 1
fi

# Check Docker Compose
if ! command -v docker-compose &> /dev/null && ! docker compose version &> /dev/null 2>&1; then
    echo -e "${RED}âŒ Docker Compose not found${NC}"
    echo "   Install Docker Compose: https://docs.docker.com/compose/install/"
    exit 1
fi

# Determine compose command
if docker compose version &> /dev/null 2>&1; then
    COMPOSE_CMD="docker compose"
else
    COMPOSE_CMD="docker-compose"
fi

echo -e "${GREEN}âœ… Docker and Compose installed${NC}"

# Ensure docker-compose (v1) can talk to the local Docker socket
if [ "$COMPOSE_CMD" = "docker-compose" ]; then
    echo "   Detected docker-compose v1 (Python CLI)"
    if ! command -v python3 > /dev/null 2>&1; then
        echo -e "${YELLOW}âš ï¸  python3 not found. Install python3 to let docker-compose talk to Docker (${NC}sudo apt install python3${YELLOW}).${NC}"
        exit 1
    fi

    if ! python3 -m pip --version > /dev/null 2>&1; then
        echo -e "${RED}âŒ pip for python3 not found.${NC}"
        echo "   Install pip: sudo apt install python3-pip"
        exit 1
    fi

    if python3 - <<'PY' > /dev/null 2>&1
import re
import sys
from itertools import zip_longest
try:
    import requests
except ModuleNotFoundError:
    sys.exit(1)

def needs_pin(current, ceiling="2.32.0"):
    def parse(v):
        nums = [int(x) for x in re.findall(r'\d+', v)]
        return nums

    cur = parse(current)
    cap = parse(ceiling)
    for a, b in zip_longest(cur, cap, fillvalue=0):
        if a > b:
            return True
        if a < b:
            return False
    return True  # equal

sys.exit(0 if needs_pin(requests.__version__) else 1)
PY
    then
        echo -e "${YELLOW}   âš ï¸ requests >= 2.32 detected (Compose v1 incompatibility). Pinning to <2.32...${NC}"
        if python3 -m pip install --user 'requests<2.32' > /dev/null; then
            echo -e "${GREEN}   âœ… requests pinned to a Compose-compatible version${NC}"
        else
            echo -e "${RED}âŒ Failed to pin requests automatically.${NC}"
            echo "   Try: python3 -m pip install --user 'requests<2.32'"
            exit 1
        fi
    else
        echo -e "${GREEN}   âœ… requests version compatible${NC}"
    fi

    if python3 - <<'PY' > /dev/null 2>&1
import importlib
import sys
sys.exit(0 if importlib.util.find_spec("requests_unixsocket") else 1)
PY
    then
        echo -e "${GREEN}   âœ… requests-unixsocket already installed${NC}"
    else
        echo -e "${YELLOW}   ğŸ“¦ Installing requests-unixsocket so docker-compose can reach Docker...${NC}"
        if python3 -m pip install --user requests-unixsocket; then
            echo -e "${GREEN}   âœ… Installed requests-unixsocket${NC}"
        else
            echo -e "${RED}âŒ Failed to install requests-unixsocket automatically.${NC}"
            echo "   Try: python3 -m pip install --user requests-unixsocket"
            exit 1
        fi
    fi
fi

# Check if running as root or in docker group
if ! docker ps &> /dev/null; then
    echo -e "${YELLOW}âš ï¸  Docker requires elevated permissions${NC}"
    echo "   Either run with sudo or add your user to docker group:"
    echo "   $ sudo usermod -aG docker \$USER && newgrp docker"
    exit 1
fi

# Check kernel version for eBPF
KERNEL_VERSION=$(uname -r | cut -d. -f1)
if [ "$KERNEL_VERSION" -lt 5 ]; then
    echo -e "${YELLOW}âš ï¸  Kernel version $(uname -r) detected${NC}"
    echo "   eBPF works best on Linux 5.0+. You may experience limited functionality."
    read -p "   Continue anyway? (y/N) " -n 1 -r
    echo ""
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        exit 1
    fi
else
    echo -e "${GREEN}âœ… Kernel $(uname -r) supports eBPF${NC}"
fi


if [ ! -d "/sys/kernel/btf" ]; then
    echo -e "${YELLOW}âš ï¸  BTF not found at /sys/kernel/btf${NC}"
    echo "   Cognitod will run in degraded mode (no per-process CPU/mem metrics)"
    echo "   To enable BTF: Upgrade kernel or install linux-headers"
else
    echo -e "${GREEN}âœ… BTF available for dynamic telemetry${NC}"
fi

# Step 2: Download demo model
echo ""
echo -e "${BLUE}[2/6]${NC} Checking for demo model..."

MODEL_PATH="./models/linnix-3b-distilled-q5_k_m.gguf"
MODEL_SIZE="2.1GB"

if [ -f "$MODEL_PATH" ]; then
    echo -e "${GREEN}âœ… Model already downloaded${NC}"
else
    mkdir -p ./models
    echo -e "${YELLOW}ğŸ“¥ Demo model not found. Will be downloaded on first container start.${NC}"
    echo "   Size: $MODEL_SIZE (may take 2-5 minutes)"
    echo "   Alternatively, download manually:"
    echo "   $ wget https://github.com/linnix-os/linnix/releases/download/v0.1.0/linnix-3b-distilled-q5_k_m.gguf -P ./models"
fi

# Step 3: Create default config if missing
echo ""
echo -e "${BLUE}[3/6]${NC} Setting up configuration..."

mkdir -p ./configs

if [ ! -f "./configs/linnix.toml" ]; then
    cat > ./configs/linnix.toml << 'EOF'
# Linnix Configuration
# Documentation: https://docs.linnix.io/configuration

[runtime]
# Offline mode: disable external HTTP requests (Slack, PagerDuty, etc.)
offline = false

[telemetry]
# Sample interval for CPU/memory metrics (milliseconds)
sample_interval_ms = 1000

# Event retention window (seconds)
retention_seconds = 60

[probes]
# Page fault tracing (high overhead - disabled by default)
enable_page_faults = false

[reasoner]
# AI-powered incident detection
enabled = true
endpoint = "http://llama-server:8090/v1/chat/completions"
model = "linnix-3b-distilled"
window_seconds = 30
timeout_ms = 30000

[prometheus]
# Prometheus metrics endpoint
enabled = true
EOF
    echo -e "${GREEN}âœ… Created default config at ./configs/linnix.toml${NC}"
else
    echo -e "${GREEN}âœ… Using existing config${NC}"
fi

# Step 4: Pull/build Docker images
echo ""
echo -e "${BLUE}[4/6]${NC} Starting Docker containers..."
echo "   This will:"
echo "   - Pull cognitod and llama-cpp images (or build if needed)"
echo "   - Download demo model (2.1GB) if not present"
echo "   - Start monitoring services"
echo ""

$COMPOSE_CMD up -d || {
    echo -e "${YELLOW}âš ï¸  Compose failed on first attempt; attempting recovery...${NC}"
    LAST_ERR=$(mktemp)
    if ! $COMPOSE_CMD up -d 2>"$LAST_ERR"; then
        if grep -q "ContainerConfig" "$LAST_ERR" || grep -q "KeyError" "$LAST_ERR"; then
            echo -e "   Detected ContainerConfig KeyError from docker-compose. Trying to remove LLM image and retry..."
            if sudo docker image rm -f ghcr.io/ggerganov/llama.cpp:server > /dev/null 2>&1; then
                echo "   Removed stale LLM image"
            fi
            if $COMPOSE_CMD up -d; then
                echo -e "${GREEN}âœ… Compose started after removing LLM image${NC}"
                rm -f "$LAST_ERR"
            else
                echo -e "${YELLOW}âš ï¸  Compose still failing. Falling back to manual LLM start and partial compose.${NC}"
                LLM_MODEL_PATH="$(pwd)/models/linnix-3b-distilled-q5_k_m.gguf"
                echo "   Starting llama-server manually (docker run)..."
                sudo docker run -d --name linnix-llm --restart unless-stopped \
                    -v "$(pwd)/models:/models:ro" -p 8090:8090 ghcr.io/ggerganov/llama.cpp:server \
                    --host 0.0.0.0 --port 8090 -m /models/$(basename "$LLM_MODEL_PATH") \
                    --alias linnix-3b-distilled --ctx-size 4096 -t 4 --log-disable || true
                sleep 2
                echo "   Bringing up remaining services (cognitod, dashboard) via compose..."
                if $COMPOSE_CMD up -d cognitod dashboard; then
                    echo -e "${GREEN}âœ… Remaining services started${NC}"
                else
                    echo -e "${RED}âŒ Failed to start remaining services via compose.${NC}"
                    echo "   Inspect compose output or try 'docker compose up -d' if available."
                    echo "   Last compose error:";
                    sed -n '1,200p' "$LAST_ERR" || true
                    rm -f "$LAST_ERR"
                    exit 1
                fi
            fi
        else
            echo -e "${RED}âŒ docker-compose failed with an unexpected error.${NC}"
            echo "   Last compose output:";
            sed -n '1,200p' "$LAST_ERR" || true
            rm -f "$LAST_ERR"
            exit 1
        fi
    fi
}

# Step 5: Wait for services to be healthy
echo ""
echo -e "${BLUE}[5/6]${NC} Waiting for services to start..."

# Wait for cognitod
echo -n "   Cognitod: "
for i in {1..30}; do
    if curl -sf http://localhost:3000/healthz > /dev/null 2>&1; then
        echo -e "${GREEN}âœ… Running${NC}"
        break
    fi
    echo -n "."
    sleep 1
    if [ $i -eq 30 ]; then
        echo -e "${RED}âŒ Timeout${NC}"
        echo "   Check logs: $COMPOSE_CMD logs cognitod"
        exit 1
    fi
done

# Wait for llama-server (may take longer due to model download)
echo -n "   LLM Server: "
for i in {1..120}; do
    if curl -sf http://localhost:8090/health > /dev/null 2>&1; then
        echo -e "${GREEN}âœ… Running${NC}"
        break
    fi
    echo -n "."
    sleep 1
    if [ $i -eq 120 ]; then
        echo -e "${RED}âŒ Timeout${NC}"
        echo "   Check logs: $COMPOSE_CMD logs llama-server"
        exit 1
    fi
done

# Step 6: Success!
echo ""
echo -e "${BLUE}[6/6]${NC} Testing AI analysis..."

# If requested, run an autodemo / fake-events generator so users see activity
if [ "$AUTO_DEMO" -eq 1 ]; then
    echo -e "${BLUE}â±ï¸  Autodemo enabled: starting demo scripts...${NC}"
    mkdir -p ./logs
    DEMO_RUN=""
    # Look for demo scripts in repo root and scripts/ directory
    CANDIDATES=("./scenarios/demo/demo-script.sh" "./demo_phase1_local.sh" "./demo_reasoner_with_processes.sh" "./scripts/demo_phase1_local.sh" "./scripts/demo_reasoner_with_processes.sh")
    for c in "${CANDIDATES[@]}"; do
        if [ -x "$c" ]; then
            DEMO_RUN="$c"
            break
        elif [ -f "$c" ]; then
            chmod +x "$c" || true
            DEMO_RUN="$c"
            break
        fi
    done
    # As a last-resort fallback, check scripts/ directory for any demo_*.sh
    if [ -z "$DEMO_RUN" ]; then
        for c in ./scripts/demo_*.sh; do
            if [ -f "$c" ]; then
                chmod +x "$c" || true
                DEMO_RUN="$c"
                break
            fi
        done
    fi

    if [ -n "$DEMO_RUN" ]; then
        echo "   Running demo: $DEMO_RUN (logs -> ./logs/autodemo.log)"
        nohup bash -c "$DEMO_RUN" > ./logs/autodemo.log 2>&1 &
        sleep 2
        echo "   Demo started (background). Tail logs with: tail -f ./logs/autodemo.log"
    else
        echo -e "${YELLOW}   No demo scripts found in repo. You can run one of the demo scripts manually:${NC}"
        echo "     ./demo_phase1_local.sh  or  ./demo_reasoner_with_processes.sh"
    fi
fi

# Test linnix-reasoner
if command -v cargo &> /dev/null; then
    echo ""
    echo "Running AI analysis (this may take 10-15 seconds)..."
    export LLM_ENDPOINT="http://localhost:8090/v1/chat/completions"
    export LLM_MODEL="linnix-3b-distilled"
    cargo run --release -p linnix-reasoner 2>/dev/null || {
        echo -e "${YELLOW}âš ï¸  Rust not installed. Run reasoner with Docker:${NC}"
        echo "   $ docker run --rm --network=host linnixos/linnix-cli linnix-reasoner"
    }
else
    echo -e "${YELLOW}âš ï¸  Rust not installed. Skipping reasoner test.${NC}"
fi

# Success message
echo ""
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘                                                            â•‘"
echo "â•‘   ğŸ‰  Linnix is running!                                   â•‘"
echo "â•‘                                                            â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo -e "${GREEN}Services:${NC}"
echo "   â€¢ Cognitod (monitoring):    http://localhost:3000"
echo "   â€¢ LLM Server:               http://localhost:8090"
echo "   â€¢ Prometheus metrics:       http://localhost:3000/metrics/prometheus"
echo ""
echo -e "${GREEN}Quick Commands:${NC}"
echo "   â€¢ View status:      $COMPOSE_CMD ps"
echo "   â€¢ View logs:        $COMPOSE_CMD logs -f"
echo "   â€¢ Get AI insights:  curl http://localhost:3000/insights"
echo "   â€¢ Stream events:    curl http://localhost:3000/stream"
echo "   â€¢ Stop services:    $COMPOSE_CMD down"
echo "   â€¢ Run demo on start: $0 --autodemo"
echo ""
echo -e "${GREEN}Next Steps:${NC}"
echo "   1. Open http://localhost:3000/status in browser"
echo "   2. Try: curl http://localhost:3000/insights | jq"
echo "   3. Install CLI: cargo install --path linnix-cli"
echo "   4. Read docs: https://docs.linnix.io"
echo ""
echo -e "${BLUE}Time to first insight: $(date +%s) seconds${NC}"
echo ""
